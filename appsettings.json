{
  "AWS": {
    "Profile": "minio",
    "Region": "us-east-1",
    "ServiceURL": "http://localhost:9000",
    "ForcePathStyle": true,
    "ProfilesLocation": ".aws/credentials"
  },
  "AwsOptions": {
    "BucketMarkdownOcr": "markdown-ocr",
    "BucketDocumentSummary": "document-summary",
    "BucketChunkQa": "chunk-qa"
  },
  "AllowedHosts": "*",
  "LlmProviders": {
    "Nvidia": {
      "BaseUrl": "https://integrate.api.nvidia.com/v1",
      "ApiKey": "",
      "Models": [
        {
          "ModelName": "mistralai/ministral-14b-instruct-2512",
          "Temperature": 0.15,
          "MaxTokens": 10240,
          "TopP": 1.0
        },
        {
          "ModelName": "openai/gpt-oss-120b",
          "Temperature": 1,
          "MaxTokens": 8192,
          "TopP": 1.0
        },
        {
          "ModelName": "openai/gpt-oss-20b",
          "Temperature": 1,
          "MaxTokens": 8192,
          "TopP": 1.0
        },
        {
          "ModelName": "deepseek-ai/deepseek-r1-0528",
          "Temperature": 0.6,
          "MaxTokens": 8192,
          "TopP": 0.7,
          "HaveThinking": true
        },
        {
          "ModelName": "deepseek-ai/deepseek-r1-distill-qwen-14b",
          "Temperature": 0.6,
          "MaxTokens": 8192,
          "TopP": 0.7,
          "HaveThinking": true
        },
        {
          "ModelName": "deepseek-ai/deepseek-v3.1-terminus",
          "Temperature": 0.2,
          "MaxTokens": 8192,
          "TopP": 0.7
        }
      ]
    },
    "Vllm": {
      "BaseUrl": "http://localhost:5000/v1",
      "ApiKey": "",
      "Models": [
        {
          "ModelName": "mistralai/ministral-14b-instruct-2512",
          "Temperature": 0.15,
          "MaxTokens": 8192
        },
        {
          "ModelName": "openai-gpt-oss-120b",
          "Temperature": 1,
          "MaxTokens": 8192
        }
      ]
    }
  },
  "TokenCountService": {
    "BaseUrl": "http://localhost:8000/"
  },
  "ChunkOption": {
    "MaxTokensPerChunk": 8192,
    "MaxDeepHeader": 5,
    "UseModelProviderForChoice": "Nvidia__mistralai/ministral-14b-instruct-2512",
    "UseModelProviderForGenQAs": "Nvidia__mistralai/ministral-14b-instruct-2512"
  },
  "SystemPrompts": {
    "Choice": {
      "SystemPrompt": "You are a data processing assistant specializing in Markdown table structure analysis.",
      "PathTemplatePrompt": "data/prompts/promptChoiceV2.md"
    },
    "GenQAsSummary": {
      "SystemPrompt": "You are a professional QA generator specializing in analyzing content and extracting high-quality Question and Answer pairs.",
      "PathTemplatePrompt": "data/prompts/promptGenQAsSummary.md"
    },
    "GenQAsText": {
      "SystemPrompt": "You are a professional QA generator specializing in analyzing content and extracting high-quality Question and Answer pairs.",
      "PathTemplatePrompt": "data/prompts/promptGenQAsChunk.md"
    },
    "GenQAsTable": {
      "SystemPrompt": "You are a professional QA generator specializing in analyzing content and extracting high-quality Question and Answer pairs.",
      "PathTemplatePrompt": "data/prompts/promptGenQAsTable.md"
    },
    "GenSummaryDocument": {
      "SystemPrompt": "You are a professional document analyst specializing in identifying the main purpose, topic, and key focus areas of documents. Your responsibility is to read the provided content and clearly determine what the document is about, who it is for, and what objectives it aims to achieve. You provide concise, objective, and accurate analysis without adding assumptions beyond the given text.",
      "PathTemplatePrompt": "data/prompts/promptGenSummaryDocument.md"
    }
  },
  "Serilog": {
    "Using": [
      "Serilog.Sinks.Console",
      "Serilog.Sinks.File"
    ],
    "MinimumLevel": {
      "Default": "Information",
      "Override": {
        "Microsoft": "Warning",
        "System": "Warning"
      }
    },
    "WriteTo": [
      {
        "Name": "Console",
        "Args": {
          "restrictedToMinimumLevel": "Information",
          "theme": "Serilog.Sinks.SystemConsole.Themes.AnsiConsoleTheme::Code, Serilog.Sinks.Console",
          "outputTemplate": "[{Timestamp:HH:mm:ss} {Level:u3}] {Message:lj}{NewLine}{Exception}"
        }
      },
      {
        "Name": "File",
        "Args": {
          "path": "Logs/log-.json",
          "rollingInterval": "Day",
          "restrictedToMinimumLevel": "Warning",
          "retainedFileCountLimit": 30,
          "formatter": "Serilog.Formatting.Json.JsonFormatter, Serilog"
        }
      }
    ],
    "Enrich": [
      "FromLogContext",
      "WithMachineName",
      "WithThreadId"
    ],
    "Properties": {
      "Application": "MarkdownGenQAs"
    }
  },
  "ConnectionStrings": {
    "DefaultConnection": "Host=localhost;Port=5432;Database=appdb;Username=appuser;Password=123456;"
  },
  "Hangfire": {
    "RedisConnection": "localhost:6379,abortConnect=false,password=MySecurePassword123",
    "DashboardPath": "/hangfire",
    "DashboardTitle": "MarkdownGenQAs Background Jobs",
    "WorkerCount": 2
  }
}