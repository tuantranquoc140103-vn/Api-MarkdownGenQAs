# MarkdownGenQAs - Markdown to QA Generation System

D·ª± √°n n√†y l√† m·ªôt h·ªá th·ªëng backend ƒë∆∞·ª£c x√¢y d·ª±ng b·∫±ng .NET 9, chuy√™n x·ª≠ l√Ω c√°c t√†i li·ªáu Markdown ƒë·ªÉ tr√≠ch xu·∫•t th√¥ng tin v√† chuy·ªÉn ƒë·ªïi th√†nh b·ªô c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi (Q&A) m·ªôt c√°ch t·ª± ƒë·ªông s·ª≠ d·ª•ng s·ª©c m·∫°nh c·ªßa c√°c Large Language Models (LLM).

## üèó Ki·∫øn tr√∫c H·ªá th·ªëng (Service Architecture)

H·ªá th·ªëng ƒë∆∞·ª£c thi·∫øt k·∫ø theo ki·∫øn tr√∫c ph√¢n l·ªõp, t√°ch bi·ªát gi·ªØa logic x·ª≠ l√Ω vƒÉn b·∫£n, t√≠ch h·ª£p LLM v√† c√°c d·ªãch v·ª• b·ªï tr·ª£.

### 1. L·ªõp Interface (Contracts)
N·∫±m trong th∆∞ m·ª•c `Interfaces/`, ƒë·ªãnh nghƒ©a c√°c b·∫£n thi·∫øt k·∫ø cho service:
- `IMarkdownService`: C√°c ph∆∞∆°ng th·ª©c x·ª≠ l√Ω c·∫•u tr√∫c Markdown.
- `IGenQAsService`: C√°c ph∆∞∆°ng th·ª©c t·∫°o Q&A.
- `ILlmChatCompletion`: Giao di·ªán chung ƒë·ªÉ t∆∞∆°ng t√°c v·ªõi c√°c LLM Provider kh√°c nhau.

### 2. L·ªõp Logic (Services)
N·∫±m trong th∆∞ m·ª•c `Services/`, th·ª±c thi c√°c nghi·ªáp v·ª• ch√≠nh:
- **MarkdownService**: 
    - Chia nh·ªè document (chunking) d·ª±a tr√™n Header Hierarchy.
    - X·ª≠ l√Ω c√°c b·∫£ng (Tables) ph·ª©c t·∫°p, c√≥ kh·∫£ nƒÉng g·ªôp c√°c b·∫£ng li√™n quan ·ªü c√°c trang kh√°c nhau (s·ª≠ d·ª•ng LLM ƒë·ªÉ quy·∫øt ƒë·ªãnh).
    - S·ª≠ d·ª•ng `TokenCountService` ƒë·ªÉ ƒë·∫£m b·∫£o m·ªói chunk kh√¥ng v∆∞·ª£t qu√° gi·ªõi h·∫°n token.
- **GenQAsService**: 
    - Nh·∫≠n v√†o c√°c chunk vƒÉn b·∫£n, summary c·ªßa document.
    - T·∫°o Prompt v√† g·ªçi LLM ƒë·ªÉ sinh ra Q&A theo ƒë·ªãnh d·∫°ng JSON Schema.
    - C√≥ c∆° ch·∫ø Retry khi LLM tr·∫£ v·ªÅ k·∫øt qu·∫£ kh√¥ng mong mu·ªën.
- **JsonService**: H·ªó tr·ª£ serialize/deserialize JSON v√† t·∫°o JSON Schema cho prompts.

### 3. L·ªõp LLM Provider (Infrastructure/Services/llms)
H·ªá th·ªëng h·ªó tr·ª£ nhi·ªÅu nh√† cung c·∫•p LLM th√¥ng qua l·ªõp tr·ª´u t∆∞·ª£ng `LlmChatCompletionBase`:
- **NvidiaService**: T√≠ch h·ª£p v·ªõi Nvidia NIM API.
- **VllmService**: T√≠ch h·ª£p v·ªõi server ch·∫°y Vllm c·ª•c b·ªô ho·∫∑c t·ª± tri·ªÉn khai.

### 4. L·ªõp Infrastructure & Factories
- **Infrastructure/Factories**: 
    - `LlmClientFactory`: Kh·ªüi t·∫°o `ChatClient` (OpenAI SDK) t∆∞∆°ng ·ª©ng v·ªõi t·ª´ng provider.
    - `LlmServiceFactory`: Resolve ƒë√∫ng service th·ª±c thi (`NvidiaService` ho·∫∑c `VllmService`) d·ª±a tr√™n c·∫•u h√¨nh trong `appsettings.json`.
- **ExternalServices**: `TokenCountService` g·ªçi ƒë·∫øn m·ªôt API b√™n ngo√†i ƒë·ªÉ ƒë·∫øm token ch√≠nh x√°c theo tokenizer c·ªßa model.

## üöÄ Lu·ªìng X·ª≠ l√Ω Ch√≠nh (Main Logic Flow)

```mermaid
graph TD
    A[Markdown Source] --> B[MarkdownService]
    B --> C{Chunking Logic}
    C -->|Header level| D[Create Chunks]
    C -->|Tables| E[Merge/Split Tables]
    D & E --> F[Chunk List]
    
    F --> G[GenQAsService]
    G --> H[GenSummaryDocumentAsync]
    H --> I[Document Summary]
    
    F & I --> J[GenQAsTextAsync / GenQAsTableAsync]
    J --> K[LLM Prompting]
    K --> L[Structured JSON Output]
    L --> M[List of Q&A]
```

## üõ† C√°ch ƒëƒÉng k√Ω v√† S·ª≠ d·ª•ng (DI & Resolution)

D·ª± √°n s·ª≠ d·ª•ng **Keyed Services** ƒë·ªÉ qu·∫£n l√Ω c√°c provider LLM:
- C√°c `ChatClient` v√† `LlmChatCompletionBase` ƒë∆∞·ª£c ƒëƒÉng k√Ω v·ªõi Key t∆∞∆°ng ·ª©ng (`LlmProvider.Nvidia`, `LlmProvider.Vllm`).
- `LlmServiceFactory` s·∫Ω ch·ªãu tr√°ch nhi·ªám `GetRequiredKeyedService` d·ª±a tr√™n c√†i ƒë·∫∑t `UseModelProviderForGenQAs` trong config.

### V√≠ d·ª• l·∫≠p tr√¨nh Controller (Future Guide)
Khi vi·∫øt Controller, b·∫°n ch·ªâ c·∫ßn Inject c√°c Interface ch√≠nh:

```csharp
public class QAsController : ControllerBase 
{
    private readonly IMarkdownService _markdownService;
    private readonly IGenQAsService _genQAsService;

    public QAsController(IMarkdownService markdownService, IGenQAsService genQAsService)
    {
        _markdownService = markdownService;
        _genQAsService = genQAsService;
    }

    [HttpPost("generate")]
    public async Task<IActionResult> Generate([FromBody] string markdown)
    {
        // 1. Chia nh·ªè vƒÉn b·∫£n
        var chunks = await _markdownService.CreateChunkDocument(markdown);
        
        // 2. T·∫°o summary (optional)
        var summary = await _genQAsService.GenSummaryDocumentAsync(markdown, "filename.md");

        // 3. Sinh Q&A cho t·ª´ng chunk
        foreach(var chunk in chunks) {
            var qas = await _genQAsService.GenQAsTextAsync(chunk, summary, "filename.md");
            // ... l∆∞u tr·ªØ ho·∫∑c tr·∫£ v·ªÅ
        }
        
        return Ok();
    }
}
```

## ‚öôÔ∏è C·∫•u h√¨nh (Configuration)
Th√¥ng tin quan tr·ªçng trong `appsettings.json`:
- `ChunkOption`: C·∫•u h√¨nh ƒë·ªô s√¢u header, max tokens, v√† provider mu·ªën d√πng.
- `LlmProviderOptions`: API Key, BaseUrl v√† Models cho t·ª´ng provider (Nvidia, Vllm).
- `SystemPrompts`: ƒê∆∞·ªùng d·∫´n ƒë·∫øn c√°c file template prompt v√† system message.
